{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"ensemble_pytorch.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"2c25571d57d046cba2c58397ddc34b19":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ca25ccb0f27245c6843719f8c9230d72","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_735369df2ed64befbf8881dfcce5ac59","IPY_MODEL_b87b07022dbf4813b8167d41eff89636","IPY_MODEL_901e1198a6dd47b1a22a5d1b3f118223"]}},"ca25ccb0f27245c6843719f8c9230d72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"735369df2ed64befbf8881dfcce5ac59":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2c3c1dd048e249f1b509608f4f6742b6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_280fb25dba9a4c71919f14860d9dca9e"}},"b87b07022dbf4813b8167d41eff89636":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_321a89271cd4410286411128362354e0","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":170498071,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":170498071,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b8001ce77991495c9b07566c3d033921"}},"901e1198a6dd47b1a22a5d1b3f118223":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_47520650afa140fa9b790b18d93a47f1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 170499072/? [00:03&lt;00:00, 48528568.92it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_315d54783e0b4990ac968204723cc721"}},"2c3c1dd048e249f1b509608f4f6742b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"280fb25dba9a4c71919f14860d9dca9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"321a89271cd4410286411128362354e0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b8001ce77991495c9b07566c3d033921":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"47520650afa140fa9b790b18d93a47f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"315d54783e0b4990ac968204723cc721":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"CspDnsdcmRze"},"source":["# BTVN: Training Neural Networks (Tiếp)\n","Trong phần này các bạn sẽ làm quen với kỹ thuật model ensemble để tăng độ chính xác khi suy diễn"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"dALhhAr_5agu","executionInfo":{"status":"error","timestamp":1638883476907,"user_tz":-420,"elapsed":502,"user":{"displayName":"Minh Sơn Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2j1sDLJ9nFTbjMwh1pIeQuSUiyuJSlxHgxuMc=s64","userId":"03159414786129788503"}},"outputId":"5312e129-852b-4ed4-ffbb-3ffc0b88ccc0"},"source":["# !nvidia-smi\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","# %cd /content/drive/MyDrive/L13_TrainingDNN\n","\n","# import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import glob\n","import cv2\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","import os\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","from torch.nn import CrossEntropyLoss, Dropout, Softmax, Linear, Conv2d, LayerNorm\n","import matplotlib.pyplot as plt\n","from torchsummary import summary"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-f796dd1948fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# import torch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m __all__ += [name for name in dir(_C)\n\u001b[0m\u001b[1;32m    230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             not name.endswith('Base')]\n","\u001b[0;31mNameError\u001b[0m: name '_C' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"1_jDYArKvZ-Z"},"source":["Tải dữ liệu và cài đặt một kiến trúc mạng nơ-ron đơn giản theo mô tả phía dưới"]},{"cell_type":"code","metadata":{"id":"ptNpnOaYCuK6","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a42080d5-2678-4726-f951-c71590c8c034"},"source":["def load_data(data_dir=\"./data\"):\n","    transform = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","    ])\n","\n","    trainset = torchvision.datasets.CIFAR10(\n","        root=data_dir, train=True, download=True, transform=transform)\n","\n","    testset = torchvision.datasets.CIFAR10(\n","        root=data_dir, train=False, download=True, transform=transform)\n","\n","    return trainset, testset\n","\n","\n","class Net(nn.Module):\n","    ######################\n","    ### YOUR CODE HERE ###\n","    def __init__(self, l1=120, l2=84):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 6, 5)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.conv2 = nn.Conv2d(6, 16, 5)\n","        self.fc1 = nn.Linear(16 * 5 * 5, l1)\n","        self.fc2 = nn.Linear(l1, l2)\n","        self.fc3 = nn.Linear(l2, 10)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = x.view(-1, 16 * 5 * 5)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","\n","        return x\n","    ######################\n","\n","model = Net()\n","if torch.cuda.is_available():\n","    model.cuda()\n","summary(model, (3, 32, 32))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 6, 28, 28]             456\n","         MaxPool2d-2            [-1, 6, 14, 14]               0\n","            Conv2d-3           [-1, 16, 10, 10]           2,416\n","         MaxPool2d-4             [-1, 16, 5, 5]               0\n","            Linear-5                  [-1, 120]          48,120\n","            Linear-6                   [-1, 84]          10,164\n","            Linear-7                   [-1, 10]             850\n","================================================================\n","Total params: 62,006\n","Trainable params: 62,006\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 0.06\n","Params size (MB): 0.24\n","Estimated Total Size (MB): 0.31\n","----------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"]}]},{"cell_type":"markdown","metadata":{"id":"vrBfyiTeCx4n"},"source":["Hàm đánh giá độ chính xác trên tập test"]},{"cell_type":"code","metadata":{"id":"GV63_UK5SqbP"},"source":["def test_accuracy(net, device=\"cpu\"):\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data in testloader:\n","            images, labels = data\n","            images, labels = images.to(device), labels.to(device)\n","            ######################\n","            ### YOUR CODE HERE ###\n","            ######################\n","\n","    return correct / total"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i3rs2a_ECx4p"},"source":["Hàm huấn luyện mô hình"]},{"cell_type":"code","metadata":{"id":"Bk1YvtHgOKqk"},"source":["def train(net, criterion, optimizer, save_path, device=\"cpu\"):\n","    T_cur = 0\n","    for epoch in range(1, epochs+1):  # loop over the dataset multiple times\n","        running_loss = 0.0\n","        epoch_steps = 0\n","        T_cur += 1\n","        \n","        # warm-up\n","        if epoch <= warm_epoch:\n","            optimizer.param_groups[0]['lr'] = (1.0 * epoch) / warm_epoch  * init_lr\n","        else: \n","            # cosine annealing lr\n","            optimizer.param_groups[0]['lr'] = last_lr + (init_lr - last_lr) * (1 + np.cos(T_cur * np.pi / T_max)) / 2\n","\n","        for i, data in enumerate(trainloader, 0):\n","            # get the inputs; data is a list of [inputs, labels]\n","            inputs, labels = data\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            # zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            # forward + backward + optimize\n","            outputs = net(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            # print statistics\n","            running_loss += loss.item()\n","            epoch_steps += 1\n","            if i + 1 == len(trainloader):\n","                print(\"[Epoch %d] loss: %.3f\" % (epoch, running_loss / epoch_steps))\n","                running_loss = 0.0\n","                \n","    print(\"Finished Training\")\n","    print(\"Test accuracy:\", test_accuracy(net, device))\n","    torch.save(net.state_dict(), save_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uJVHnV-xCx4t"},"source":["Thiết lập các tham số và hai kiến trúc mạng khác nhau"]},{"cell_type":"code","metadata":{"id":"mS4soUx9iwvh","colab":{"base_uri":"https://localhost:8080/","height":100,"referenced_widgets":["2c25571d57d046cba2c58397ddc34b19","ca25ccb0f27245c6843719f8c9230d72","735369df2ed64befbf8881dfcce5ac59","b87b07022dbf4813b8167d41eff89636","901e1198a6dd47b1a22a5d1b3f118223","2c3c1dd048e249f1b509608f4f6742b6","280fb25dba9a4c71919f14860d9dca9e","321a89271cd4410286411128362354e0","b8001ce77991495c9b07566c3d033921","47520650afa140fa9b790b18d93a47f1","315d54783e0b4990ac968204723cc721"]},"outputId":"c054257d-2fdd-4379-8e42-bca90aa16904"},"source":["epochs = 10\n","warm_epoch = 5\n","init_lr = 1e-2\n","last_lr = 1e-4\n","T_max = epochs\n","\n","configs = [{'l1': 64, 'l2': 32}, {'l1': 128, 'l2': 64}]\n","\n","trainset, testset = load_data('./data')\n","trainloader = torch.utils.data.DataLoader(\n","    trainset,\n","    batch_size=128,\n","    shuffle=True,\n",")\n","testloader = torch.utils.data.DataLoader(\n","    testset, batch_size=4, shuffle=False, num_workers=2)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2c25571d57d046cba2c58397ddc34b19","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/170498071 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n"]}]},{"cell_type":"markdown","metadata":{"id":"nsCaZgt2Cx4x"},"source":["Huấn luyện hai mạng mô tả trong configs"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rHabW0HfNQuj","outputId":"4a4c9bd0-7994-498b-c44e-fd7dadb46dd5"},"source":["os.makedirs('./snapshot', exist_ok=True)\n","\n","for i, cfg in enumerate(configs):\n","    print(cfg)\n","    net = Net(cfg['l1'], cfg['l2'])\n","    ######################\n","    ### YOUR CODE HERE ###\n","    ######################"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'l1': 64, 'l2': 32}\n","[Epoch 1] loss: 2.293\n","[Epoch 2] loss: 1.969\n","[Epoch 3] loss: 1.645\n","[Epoch 4] loss: 1.464\n","[Epoch 5] loss: 1.346\n","[Epoch 6] loss: 1.205\n","[Epoch 7] loss: 1.150\n","[Epoch 8] loss: 1.112\n","[Epoch 9] loss: 1.093\n","[Epoch 10] loss: 1.085\n","Finished Training\n","Test accuracy: 0.5958\n","{'l1': 128, 'l2': 64}\n","[Epoch 1] loss: 2.303\n","[Epoch 2] loss: 2.249\n","[Epoch 3] loss: 1.819\n","[Epoch 4] loss: 1.558\n","[Epoch 5] loss: 1.394\n","[Epoch 6] loss: 1.224\n","[Epoch 7] loss: 1.164\n","[Epoch 8] loss: 1.123\n","[Epoch 9] loss: 1.100\n","[Epoch 10] loss: 1.091\n","Finished Training\n","Test accuracy: 0.5889\n"]}]},{"cell_type":"markdown","metadata":{"id":"4vY-sXfrCx4y"},"source":["Kết hợp kết quả hai mạng (ensemble)"]},{"cell_type":"code","metadata":{"id":"_W4q6zccShD5"},"source":["from tqdm import tqdm\n","\n","def test_ensemble(device=\"cuda:0\"):\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data in tqdm(testloader):\n","            images, labels = data\n","            images, labels = images.to(device), labels.to(device)\n","            final_outputs = torch.zeros((4, 10)).to(device)\n","            for i, cfg in enumerate(configs):\n","                net = Net(cfg['l1'], cfg['l2'])\n","                net.to(device) \n","                net.load_state_dict(torch.load(f'./snapshot/model{i}.pth'))               \n","                outputs = net(images)\n","                final_outputs = final_outputs.add(outputs)\n","\n","            final_outputs.div(len(configs))\n","            _, predicted = torch.max(final_outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    return correct / total"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VXNrqlJrCx40"},"source":["from tqdm import tqdm\n","\n","def test_ensemble(device=\"cuda:0\"):\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data in tqdm(testloader):\n","            images, labels = data\n","            images, labels = images.to(device), labels.to(device)\n","            final_outputs = torch.zeros((4, 10)).to(device)\n","            for i, cfg in enumerate(configs):\n","                net = Net(cfg['l1'], cfg['l2'])\n","                net.to(device) \n","                net.load_state_dict(torch.load(f'./snapshot/model{i}.pth'))               \n","                outputs = net(images)\n","                final_outputs = final_outputs.add(outputs)\n","\n","            final_outputs.div(len(configs))\n","            _, predicted = torch.max(final_outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    return correct / total"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S-zwy7Uxcmmh","outputId":"9c7ae6ee-e714-47e6-cba0-99ad31f993d3"},"source":["test_ensemble()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 2500/2500 [00:37<00:00, 67.16it/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["0.6165"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"7RsZiih2dQS2"},"source":[""],"execution_count":null,"outputs":[]}]}